{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "24d25724",
   "metadata": {},
   "outputs": [],
   "source": [
    "import doom_env \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import namedtuple, deque,Counter\n",
    "import os\n",
    "import cv2\n",
    "import glob\n",
    "from gym.wrappers import Monitor\n",
    "from gym.core import ObservationWrapper\n",
    "from gym.spaces.box import Box \n",
    "import time\n",
    "\n",
    "PATH = 'last_brain.pth'\n",
    "# Defining one Step\n",
    "Step = namedtuple('Step', ['state', 'action', 'reward', 'done'])\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25937cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PreprocessImage(ObservationWrapper):\n",
    "    \n",
    "    def __init__(self, env, height = 64, width = 64, grayscale = True, crop = lambda img: img):\n",
    "        super(PreprocessImage, self).__init__(env)\n",
    "        self.img_size = (height, width)\n",
    "        self.grayscale = grayscale\n",
    "        self.crop = crop\n",
    "        n_colors = 1 if self.grayscale else 3\n",
    "        self.observation_space = Box(0.0, 1.0, [n_colors, height, width])\n",
    "\n",
    "    def observation(self, img):\n",
    "        img = self.crop(img)\n",
    "        img = cv2.resize(img,self.img_size,interpolation = cv2.INTER_CUBIC)\n",
    "        if self.grayscale:\n",
    "            img = img.mean(-1, keepdims = True)\n",
    "        img = np.transpose(img, (2, 0, 1))\n",
    "        img = img.astype('float32') / 255.\n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f1d50946",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self,num_actions):\n",
    "        super(CNN,self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1,out_channels = 32,kernel_size = 5)\n",
    "        self.conv2 = nn.Conv2d(32,32,3)\n",
    "        self.conv3 = nn.Conv2d(32,64,2)\n",
    "        self.fc1 = nn.Linear(self.count_neurons((1,64,64)),40)\n",
    "        self.fc2 = nn.Linear(40,num_actions)\n",
    "\n",
    "    def count_neurons(self,image_dim):\n",
    "        x = Variable(torch.rand(1,*image_dim))\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x),3,2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2(x),3,2))\n",
    "        x = F.relu(F.max_pool2d(self.conv3(x),3,2))\n",
    "        return x.data.view(1,-1).size(1)\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x),3,2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2(x),3,2))\n",
    "        x = F.relu(F.max_pool2d(self.conv3(x),3,2))\n",
    "        x =x.view(x.size(0),-1)\n",
    "        x = self.fc2(F.relu(self.fc1(x)))\n",
    "        return x\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0aaabc4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SoftMaxBody(nn.Module):\n",
    "    def __init__(self,temperature):\n",
    "        super(SoftMaxBody,self).__init__()\n",
    "        self.temperature = temperature\n",
    "    \n",
    "    def forward(self,outputs):\n",
    "        probs = F.softmax(outputs*self.temperature)\n",
    "        action = probs.multinomial(num_samples=1)\n",
    "        return action\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ffb845ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AI:\n",
    "    def __init__(self,brain,body,useGPU=True):\n",
    "        self.brain = brain \n",
    "        self.body = body \n",
    "        self.useGPU = useGPU\n",
    "\n",
    "    def __call__(self,inputs_):\n",
    "        #Converting the images into torch variable\n",
    "        inputs = Variable(torch.from_numpy(np.array(inputs_,dtype=np.float32)))\n",
    "        if self.useGPU:\n",
    "            if not inputs.is_cuda:\n",
    "                inputs = inputs.to(device)\n",
    "        outputs = self.brain(inputs).to('cpu')\n",
    "        action = self.body(outputs)\n",
    "\n",
    "        #returning action as numpy array\n",
    "        return action.data.numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aa748a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making the AI progress on several (n_step) steps\n",
    "class NStepProgress:\n",
    "    \n",
    "    def __init__(self, env, ai, n_step):\n",
    "        self.ai = ai\n",
    "        self.rewards = []\n",
    "        self.env = env\n",
    "        self.n_step = n_step\n",
    "    \n",
    "    def __iter__(self):\n",
    "        state = self.env.reset()\n",
    "        history = deque()\n",
    "        reward = 0.0\n",
    "        while True:\n",
    "            action = self.ai(np.array([state]))[0][0]\n",
    "            next_state, r, is_done, _ = self.env.step(action)\n",
    "            reward += r\n",
    "            history.append(Step(state = state, action = action, reward = r, done = is_done))\n",
    "            while len(history) > self.n_step + 1:\n",
    "                history.popleft()\n",
    "            if len(history) == self.n_step + 1:\n",
    "                yield tuple(history)\n",
    "            state = next_state\n",
    "            if is_done:\n",
    "                if len(history) > self.n_step + 1:\n",
    "                    history.popleft()\n",
    "                while len(history) >= 1:\n",
    "                    yield tuple(history)\n",
    "                    history.popleft()\n",
    "                self.rewards.append(reward)\n",
    "                reward = 0.0\n",
    "                state = self.env.reset()\n",
    "                history.clear()\n",
    "    \n",
    "    def rewards_steps(self):\n",
    "        rewards_step = self.rewards\n",
    "        self.rewards = []\n",
    "        return rewards_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6b057373",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementing Experience Replay\n",
    "\n",
    "class ReplayMemory:\n",
    "    \n",
    "    def __init__(self, n_steps, capacity = 10000):\n",
    "        self.capacity = capacity\n",
    "        self.n_steps = n_steps\n",
    "        self.n_steps_iter = iter(n_steps)\n",
    "        self.buffer = deque()\n",
    "        \n",
    "    # creates an iterator that returns random batches\n",
    "    def sample_batch(self, batch_size): \n",
    "        ofs = 0\n",
    "        vals = list(self.buffer)\n",
    "        np.random.shuffle(vals)\n",
    "        while (ofs+1)*batch_size <= len(self.buffer):\n",
    "            yield vals[ofs*batch_size:(ofs+1)*batch_size]\n",
    "            ofs += 1\n",
    "\n",
    "    def run_steps(self, samples):\n",
    "        while samples > 0:\n",
    "            # 10 consecutive steps\n",
    "            entry = next(self.n_steps_iter) \n",
    "            \n",
    "            # we put 200 for the current episode\n",
    "            self.buffer.append(entry) \n",
    "            samples -= 1\n",
    "            \n",
    "        # we accumulate no more than the capacity (10000)\n",
    "        while len(self.buffer) > self.capacity: \n",
    "            self.buffer.popleft()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a47cdf60",
   "metadata": {},
   "source": [
    "### Eligibility Trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "13ceb10c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eligibilityTrace(batch):\n",
    "    gamma = 0.99\n",
    "    inputs = []\n",
    "    targets = []\n",
    "    \n",
    "    for series in batch:\n",
    "        input_ = Variable(torch.from_numpy(np.array([series[0].state,series[-1].state],dtype=np.float32))).to(device)\n",
    "        output = cnn(input_)\n",
    "        \n",
    "        #Updating the cummulative reward based on last transition of the series is over or not\n",
    "        cummul_reward = 0.0 if series[-1].done else output[1].data.max()\n",
    "        \n",
    "        for step in reversed(series[:-1]):\n",
    "            cummul_reward = step.reward + cummul_reward*gamma\n",
    "            \n",
    "        #State of first transition\n",
    "        state = series[0].state\n",
    "        \n",
    "        #Q-val of input-state of first transition\n",
    "        target = output[0].data\n",
    "        \n",
    "        target[series[0].action] = cummul_reward\n",
    "        \n",
    "        inputs.append(state)\n",
    "        targets.append(target)\n",
    "    return torch.from_numpy(np.array(inputs,dtype=np.float32)), torch.stack(targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70aef4ba",
   "metadata": {},
   "source": [
    "### Making moving average on 100 steps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "21243907",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MA:\n",
    "    def __init__(self,size=100):\n",
    "        self.size = size\n",
    "        self.list_of_rewards = []\n",
    "        \n",
    "    def add(self,rewards):\n",
    "        if isinstance(rewards,list):\n",
    "            self.list_of_rewards += rewards\n",
    "        else:\n",
    "            self.list_of_rewards.append(rewards)\n",
    "        \n",
    "        #Maintaining the size of the reward list\n",
    "        while len(self.list_of_rewards) > self.size:\n",
    "            del self.list_of_rewards[0]\n",
    "    def average(self):\n",
    "        return np.mean(self.list_of_rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1ffba375",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Creating GAME Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9d2c3dc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cheth\\AppData\\Roaming\\Python\\Python39\\site-packages\\gym\\logger.py:34: UserWarning: \u001b[33mWARN: Trying to monitor an environment which has no 'spec' set. This usually means you did not create it via 'gym.make', and is recommended only for advanced users.\u001b[0m\n",
      "  warnings.warn(colorize(\"%s: %s\" % (\"WARN\", msg % args), \"yellow\"))\n"
     ]
    }
   ],
   "source": [
    "env = doom_env.VizDoomGym()\n",
    "env = Monitor(env, \"./videos\", force = True)\n",
    "num_actions = env.action_space.n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb702b99",
   "metadata": {},
   "source": [
    "### Building AI\n",
    "#### Loading model if exits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "78cec8bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load(PATH)\n",
    "\n",
    "cnn = CNN(num_actions=7)\n",
    "cnn.to(device)\n",
    "cnn.load_state_dict(checkpoint['state_dict'])\n",
    "cnn.eval()\n",
    "\n",
    "softmax_body = SoftMaxBody(temperature=50)\n",
    "ai = AI(brain=cnn,body=softmax_body)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ab4df8e",
   "metadata": {},
   "source": [
    "### Experience Replay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3d1f7a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = NStepProgress(env = env, ai = ai,n_step = 10)\n",
    "memory = ReplayMemory(n_steps=n_steps)\n",
    "\n",
    "movingAvg = MA(100)\n",
    "\n",
    "#Training the AI\n",
    "loss_func = nn.MSELoss()\n",
    "optimizer = optim.Adam(cnn.parameters(),lr=0.001)\n",
    "optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "num_epocs = 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2827403d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cheth\\AppData\\Local\\Temp/ipykernel_9176/2628048859.py:7: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  probs = F.softmax(outputs*self.temperature)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1, Average Reward : 214.93863747336647\n",
      "Epoch : 2, Average Reward : 166.6723095703125\n",
      "Epoch : 3, Average Reward : 156.23417502955385\n",
      "Epoch : 4, Average Reward : 144.62301232679835\n",
      "Epoch : 5, Average Reward : 139.58223100142047\n",
      "Epoch : 6, Average Reward : 139.46278858184814\n",
      "Epoch : 7, Average Reward : 146.77168323682702\n",
      "Epoch : 8, Average Reward : 148.13127487182618\n",
      "Epoch : 9, Average Reward : 146.0398712158203\n",
      "Epoch : 10, Average Reward : 149.16573364257812\n",
      "Training finished...\n",
      "Saving model...\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "print('Training...')\n",
    "for epoch in range(1,num_epocs+1):\n",
    "    memory.run_steps(200)\n",
    "    for batch in memory.sample_batch(128):\n",
    "        inputs,targets = eligibilityTrace(batch)\n",
    "        inputs,targets = Variable(inputs),Variable(targets)\n",
    "        predictions = cnn(inputs.to(device))\n",
    "        loss_error = loss_func(predictions,targets)\n",
    "        \n",
    "        #Clearing previous gradients\n",
    "        optimizer.zero_grad()\n",
    "        loss_error.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    #Computing avg. rewards\n",
    "    rewards_steps = n_steps.rewards_steps()\n",
    "    movingAvg.add(rewards_steps)\n",
    "    avg_reward = movingAvg.average()\n",
    "        \n",
    "    print(\"Epoch : %s, Average Reward : %s\" % (str(epoch),str(avg_reward)))\n",
    "print('Training finished...')\n",
    "print('Saving model...')\n",
    "torch.save({\n",
    "            'state_dict':cnn.state_dict(),\n",
    "            'optimizer':optimizer.state_dict()\n",
    "        },'last_brain.pth')\n",
    "print('Done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "256fb4a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "### AI-Automovement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4afdfc1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reward : 0.0\n",
      "Reward : 0.78125\n",
      "Reward : 9.571823120117188\n",
      "Reward : 17.305709838867188\n",
      "Reward : -0.9128875732421875\n",
      "Reward : 9.464981079101562\n",
      "Reward : 15.615982055664062\n",
      "Reward : 21.382583618164062\n",
      "Reward : 25.272293090820312\n",
      "Reward : 27.89593505859375\n",
      "Reward : 29.66558837890625\n",
      "Reward : 31.014480590820312\n",
      "Reward : -93.66749572753906\n"
     ]
    }
   ],
   "source": [
    "environment = doom_env.VizDoomGym(gray_scale=False)\n",
    "observation = environment.reset()\n",
    "img_array = []\n",
    "\n",
    "while True:\n",
    "    img_array.append(observation)\n",
    "    gray_img = cv2.cvtColor(np.moveaxis(observation,0,-1),cv2.COLOR_BGR2GRAY)\n",
    "    state = cv2.resize(gray_img,(64,64),interpolation = cv2.INTER_CUBIC)\n",
    "    state = np.reshape(state,(1,64,64))\n",
    "    actions = cnn(Variable(torch.from_numpy(np.array([state],dtype=np.float32)).to(device)))\n",
    "    action = np.argmax(actions.detach().to('cpu').numpy(), axis=-1)[0]\n",
    "    new_observation, reward, done, _ = environment.step(action)\n",
    "    observation = new_observation\n",
    "    time.sleep(1)\n",
    "    print('Reward :',reward)\n",
    "    if done:\n",
    "        break\n",
    "environment.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6c3130f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = np.array(img_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "95ddd1f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_name = \"videos\"\n",
    "video_name = \"play.mp4\"\n",
    "\n",
    "if not os.path.exists(folder_name):\n",
    "    os.makedirs(folder_name)\n",
    "\n",
    "for i in range(len(img_array)):\n",
    "    plt.imsave(\"{}/image{}.jpg\".format(folder_name, i),np.moveaxis(images[i],0,-1))\n",
    "\n",
    "files = glob.glob(os.path.expanduser(\"{}/*\".format(folder_name)))\n",
    "frames_array = []\n",
    "\n",
    "for filename in sorted(files, key=lambda t: os.stat(t).st_mtime):\n",
    "    img = cv2.imread(filename)\n",
    "    height, width, layers = img.shape\n",
    "    size = (width,height)\n",
    "    frames_array.append(img)\n",
    "\n",
    "out = cv2.VideoWriter(video_name, cv2.VideoWriter_fourcc(*'DIVX'), 15, size)\n",
    "\n",
    "for i in range(len(frames_array)):\n",
    "    out.write(frames_array[i])\n",
    "\n",
    "out.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d3fe3c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
